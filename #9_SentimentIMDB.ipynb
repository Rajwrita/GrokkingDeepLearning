{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "#9_SentimentIMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariG23498/GrokkingDeepLearning/blob/master/%239_SentimentIMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMf-nNpMuZRy",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bTDrGcmCMaT",
        "colab_type": "code",
        "outputId": "ea472f33-f96d-46e5-9464-f12c9e9ab128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from sklearn.utils import shuffle\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_O6Cul4DJLk",
        "colab_type": "code",
        "outputId": "1c1ac16b-dfaa-48b5-be9e-b975e5534d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-2ymhtDCMaa",
        "colab_type": "code",
        "outputId": "c741cdc8-fd7a-47f9-80b1-7d769a63ff2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Datasets/imdb_master.csv', encoding='latin-1')\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "df = shuffle(df)\n",
        "df.head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>file</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69853</th>\n",
              "      <td>train</td>\n",
              "      <td>I haven't seen something like this since the H...</td>\n",
              "      <td>unsup</td>\n",
              "      <td>2786_0.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68471</th>\n",
              "      <td>train</td>\n",
              "      <td>There are lots of these films. Generally, thes...</td>\n",
              "      <td>unsup</td>\n",
              "      <td>26625_0.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95719</th>\n",
              "      <td>train</td>\n",
              "      <td>I stumbled upon this movie on TCM already in p...</td>\n",
              "      <td>unsup</td>\n",
              "      <td>6148_0.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27453</th>\n",
              "      <td>train</td>\n",
              "      <td>As an Army veteran, I was deeply offended by t...</td>\n",
              "      <td>neg</td>\n",
              "      <td>12208_2.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88826</th>\n",
              "      <td>train</td>\n",
              "      <td>But you may easily be disappointed, if you see...</td>\n",
              "      <td>unsup</td>\n",
              "      <td>44945_0.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        type  ...         file\n",
              "69853  train  ...   2786_0.txt\n",
              "68471  train  ...  26625_0.txt\n",
              "95719  train  ...   6148_0.txt\n",
              "27453  train  ...  12208_2.txt\n",
              "88826  train  ...  44945_0.txt\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpc7fUFa5agq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(df[df['label'] == 'unsup'].index, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DQbcg6uCMah",
        "colab_type": "code",
        "outputId": "5775f637-b459-4c7a-b6dc-3a90f82d2683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['label'].unique()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neg', 'pos'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9RbXAknCMam",
        "colab_type": "code",
        "outputId": "22796bfd-d281-4d3c-8040-d8b7cf96b031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "df['label'].unique()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHf67kAaCMar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = df[df['type'] == 'train'].drop(columns=['type','file']).values\n",
        "test = df[df['type'] == 'test'].drop(columns=['type','file']).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQLpCNiBCMaw",
        "colab_type": "code",
        "outputId": "c281ce5c-3e5e-4790-a028-44e6f06687a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Length of Train: {}'.format(len(train)))\n",
        "print('Length of Test: {}'.format(len(test)))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Train: 25000\n",
            "Length of Test: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_zIkysQCMa1",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mu6b7DiMdId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(sentence):\n",
        "  # Tokenize Contents\n",
        "  contentsTokenized = nltk.tokenize.word_tokenize(sentence)\n",
        "\n",
        "  # Remove the stop_words\n",
        "  stop_word_set = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "  filteredContents_afterstop = []\n",
        "  for word in contentsTokenized:\n",
        "    if word not in stop_word_set:\n",
        "      filteredContents_afterstop.append(word)\n",
        "  \n",
        "  # Performing porterStemming\n",
        "  porterStemmer = nltk.stem.PorterStemmer()\n",
        "  filteredContents = [porterStemmer.stem(word) for word in filteredContents_afterstop]\n",
        "\n",
        "  # Remove Punctuations\n",
        "  excludePunctuation = set(string.punctuation)\n",
        "    \n",
        "  # manually add additional punctuation to remove\n",
        "  doubleSingleQuote = '\\'\\''\n",
        "  doubleDash = '--'\n",
        "  doubleTick = '``'\n",
        "\n",
        "  excludePunctuation.add(doubleSingleQuote)\n",
        "  excludePunctuation.add(doubleDash)\n",
        "  excludePunctuation.add(doubleTick)\n",
        "\n",
        "  filteredContents_afterpunc = []\n",
        "  for word in filteredContents_afterstop:\n",
        "    if word not in excludePunctuation:\n",
        "      filteredContents_afterpunc.append(word)\n",
        "\n",
        "  # Convert all to lower case\n",
        "  filteredContents_lower = [term.lower() for term in filteredContents_afterpunc]\n",
        "  return filteredContents_lower"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_XlgamSCMa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token is a list of set\n",
        "# each set consists of words in the a particular review\n",
        "\n",
        "token = list(map(lambda x: set(preprocess(x)),train[:,0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyk8xypOPUQ2",
        "colab_type": "code",
        "outputId": "5e43eb1e-90b0-45b0-f9fa-0b1616d02007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(token))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2_-XT8qCMa7",
        "colab_type": "code",
        "outputId": "0e922d21-da08-4250-df09-36c3edc59069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Total vocabulary\n",
        "vocab = set()\n",
        "for sentence in token:\n",
        "    for word in sentence:\n",
        "        if(len(word)>0):\n",
        "            vocab.add(word)\n",
        "vocab = list(vocab)\n",
        "\n",
        "print('Total vocabulary count: {}'.format(len(vocab)))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total vocabulary count: 114763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1rndxPCCMbA",
        "colab_type": "code",
        "outputId": "7b403d1e-32a4-4e3f-87d0-c7da6ff00ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# For each word in vocab there is an index\n",
        "word2index = {}\n",
        "for i,word in enumerate(vocab):\n",
        "    word2index[word] = i\n",
        "print('Total word2index count: {}'.format(len(word2index)))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total word2index count: 114763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l30p-SMBFzTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1S4s7-dCMbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_dataset is used to keep the values of each words in each sentence\n",
        "input_dataset = list()\n",
        "for sentence in token:\n",
        "    sent_indices = list()\n",
        "    for word in sentence:\n",
        "        try:\n",
        "            sent_indices.append(word2index[word])\n",
        "        except:\n",
        "            \"\"\n",
        "    input_dataset.append(list(sent_indices))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saaej-JgXJhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = input_dataset\n",
        "y_train = train[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsFRUbbeve00",
        "colab_type": "code",
        "outputId": "1efdf9e5-5387-4ff5-c82c-d289019de8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print('Type of X_train: {}'.format(type(X_train)))\n",
        "print('Len of X_train: {}'.format(len(X_train)))\n",
        "print()\n",
        "print('Type of y_train: {}'.format(type(y_train)))\n",
        "print('Type of y_train: {}'.format(len(y_train)))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of X_train: <class 'list'>\n",
            "Len of X_train: 25000\n",
            "\n",
            "Type of y_train: <class 'numpy.ndarray'>\n",
            "Type of y_train: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_tQZ_PZwUOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKjFWSMMycMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkKLQFHIzJJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha,iteration = (0.01, 2)\n",
        "hidden_size = 1000\n",
        "\n",
        "weight_0_1 = 0.2*np.random.random((len(vocab),hidden_size)) - 0.1\n",
        "weight_1_2 = 0.2*np.random.random((hidden_size,1)) - 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL_7G_gU286_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOBMN3ro1CNw",
        "colab_type": "code",
        "outputId": "3eb8170f-0710-4b9d-f3ef-9436069f54b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "for iter in range(iteration):\n",
        "  for i in range(len(X_train)):\n",
        "    x,y = X_train[i], y_train[i]\n",
        "    layer_1 = sigmoid(np.sum(weight_0_1[x],axis=0))\n",
        "    layer_2 = sigmoid(np.dot(layer_1,weight_1_2))\n",
        "\n",
        "    layer_2_delta = layer_2 - y\n",
        "    layer_1_delta = layer_2_delta.dot(weight_1_2.T)\n",
        "\n",
        "    weight_0_1[x] -= layer_1_delta * alpha\n",
        "    weight_1_2 -= np.outer(layer_1,layer_2_delta) * alpha\n",
        "\n",
        "    if(np.abs(layer_2_delta) < 0.5):\n",
        "      correct += 1\n",
        "    total += 1\n",
        "\n",
        "    if(total % 1000 == 0):\n",
        "      print('Progress: {} Training Accuracy: {}'.format(total, correct/total))\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress: 1000 Training Accuracy: 0.61\n",
            "Progress: 2000 Training Accuracy: 0.66\n",
            "Progress: 3000 Training Accuracy: 0.6913333333333334\n",
            "Progress: 4000 Training Accuracy: 0.7165\n",
            "Progress: 5000 Training Accuracy: 0.7318\n",
            "Progress: 6000 Training Accuracy: 0.7436666666666667\n",
            "Progress: 7000 Training Accuracy: 0.7558571428571429\n",
            "Progress: 8000 Training Accuracy: 0.762375\n",
            "Progress: 9000 Training Accuracy: 0.7706666666666667\n",
            "Progress: 10000 Training Accuracy: 0.7772\n",
            "Progress: 11000 Training Accuracy: 0.7839090909090909\n",
            "Progress: 12000 Training Accuracy: 0.7886666666666666\n",
            "Progress: 13000 Training Accuracy: 0.7943846153846154\n",
            "Progress: 14000 Training Accuracy: 0.7989285714285714\n",
            "Progress: 15000 Training Accuracy: 0.8034\n",
            "Progress: 16000 Training Accuracy: 0.805875\n",
            "Progress: 17000 Training Accuracy: 0.8075882352941176\n",
            "Progress: 18000 Training Accuracy: 0.8099444444444445\n",
            "Progress: 19000 Training Accuracy: 0.8128421052631579\n",
            "Progress: 20000 Training Accuracy: 0.8146\n",
            "Progress: 21000 Training Accuracy: 0.8164285714285714\n",
            "Progress: 22000 Training Accuracy: 0.8177272727272727\n",
            "Progress: 23000 Training Accuracy: 0.8195217391304348\n",
            "Progress: 24000 Training Accuracy: 0.8209166666666666\n",
            "Progress: 25000 Training Accuracy: 0.82224\n",
            "Progress: 26000 Training Accuracy: 0.8243461538461538\n",
            "Progress: 27000 Training Accuracy: 0.8272962962962963\n",
            "Progress: 28000 Training Accuracy: 0.8293214285714285\n",
            "Progress: 29000 Training Accuracy: 0.8322413793103448\n",
            "Progress: 30000 Training Accuracy: 0.8342\n",
            "Progress: 31000 Training Accuracy: 0.8365483870967741\n",
            "Progress: 32000 Training Accuracy: 0.83890625\n",
            "Progress: 33000 Training Accuracy: 0.8410909090909091\n",
            "Progress: 34000 Training Accuracy: 0.843\n",
            "Progress: 35000 Training Accuracy: 0.8452571428571428\n",
            "Progress: 36000 Training Accuracy: 0.8473611111111111\n",
            "Progress: 37000 Training Accuracy: 0.849\n",
            "Progress: 38000 Training Accuracy: 0.8506052631578948\n",
            "Progress: 39000 Training Accuracy: 0.8523846153846154\n",
            "Progress: 40000 Training Accuracy: 0.854325\n",
            "Progress: 41000 Training Accuracy: 0.8556585365853658\n",
            "Progress: 42000 Training Accuracy: 0.8565952380952381\n",
            "Progress: 43000 Training Accuracy: 0.8578139534883721\n",
            "Progress: 44000 Training Accuracy: 0.8591818181818182\n",
            "Progress: 45000 Training Accuracy: 0.8599555555555556\n",
            "Progress: 46000 Training Accuracy: 0.8612826086956522\n",
            "Progress: 47000 Training Accuracy: 0.8621489361702128\n",
            "Progress: 48000 Training Accuracy: 0.8633125\n",
            "Progress: 49000 Training Accuracy: 0.8642244897959184\n",
            "Progress: 50000 Training Accuracy: 0.86526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcde0KtH72Nw",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gldskekE5-Wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token = list(map(lambda x: set(preprocess(x)),test[:,0]))\n",
        "\n",
        "# input_dataset is used to keep the values of each words in each sentence\n",
        "input_dataset_test = list()\n",
        "for sentence in token:\n",
        "    sent_indices = list()\n",
        "    for word in sentence:\n",
        "        try:\n",
        "            sent_indices.append(word2index[word])\n",
        "        except:\n",
        "            \"\"\n",
        "    input_dataset_test.append(list(sent_indices))\n",
        "\n",
        "X_test = input_dataset_test\n",
        "y_test = test[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS2ef5mx_F5X",
        "colab_type": "code",
        "outputId": "a6dc973b-2085-497e-e9eb-a067af50bbf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_test)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLeMT0IP87N9",
        "colab_type": "code",
        "outputId": "1556bec9-54ce-4c75-ef83-c48abce77716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "correct,total = 0,0\n",
        "for i in range(len(X_test)):\n",
        "    x,y = X_test[i], y_test[i]\n",
        "    layer_1 = sigmoid(np.sum(weight_0_1[x],axis=0))\n",
        "    layer_2 = sigmoid(np.dot(layer_1,weight_1_2))\n",
        "\n",
        "    layer_2_delta = layer_2 - y\n",
        "    layer_1_delta = layer_2_delta.dot(weight_1_2.T)\n",
        "\n",
        "    if(np.abs(layer_2_delta) < 0.5):\n",
        "      correct += 1\n",
        "    total += 1\n",
        "\n",
        "    if(total % 1000 == 0):\n",
        "      print('Progress: {} Testing Accuracy: {}'.format(total, correct/total))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress: 1000 Testing Accuracy: 0.878\n",
            "Progress: 2000 Testing Accuracy: 0.87\n",
            "Progress: 3000 Testing Accuracy: 0.8723333333333333\n",
            "Progress: 4000 Testing Accuracy: 0.86975\n",
            "Progress: 5000 Testing Accuracy: 0.8698\n",
            "Progress: 6000 Testing Accuracy: 0.8676666666666667\n",
            "Progress: 7000 Testing Accuracy: 0.8671428571428571\n",
            "Progress: 8000 Testing Accuracy: 0.8705\n",
            "Progress: 9000 Testing Accuracy: 0.8698888888888889\n",
            "Progress: 10000 Testing Accuracy: 0.8704\n",
            "Progress: 11000 Testing Accuracy: 0.8704545454545455\n",
            "Progress: 12000 Testing Accuracy: 0.8704166666666666\n",
            "Progress: 13000 Testing Accuracy: 0.8704615384615385\n",
            "Progress: 14000 Testing Accuracy: 0.87\n",
            "Progress: 15000 Testing Accuracy: 0.869\n",
            "Progress: 16000 Testing Accuracy: 0.8681875\n",
            "Progress: 17000 Testing Accuracy: 0.868764705882353\n",
            "Progress: 18000 Testing Accuracy: 0.8695555555555555\n",
            "Progress: 19000 Testing Accuracy: 0.8687368421052631\n",
            "Progress: 20000 Testing Accuracy: 0.86785\n",
            "Progress: 21000 Testing Accuracy: 0.8674285714285714\n",
            "Progress: 22000 Testing Accuracy: 0.867\n",
            "Progress: 23000 Testing Accuracy: 0.8661304347826086\n",
            "Progress: 24000 Testing Accuracy: 0.8657083333333333\n",
            "Progress: 25000 Testing Accuracy: 0.86528\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}